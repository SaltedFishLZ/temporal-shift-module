hmdb51: 51 classes
storing name: TSM_hmdb51_RGB_resnet50_shift8_blockres_avg_segment8_e25

    Initializing TSN with base model: resnet50.
    TSN Configurations:
        input_modality:     RGB
        num_segments:       8
        new_length:         1
        consensus_module:   avg
        dropout_ratio:      0.8
        img_feature_dim:    256
            
=> base model: resnet50
Adding temporal shift...
=> n_segment per stage: [8, 8, 8, 8]
=> Processing stage with 3 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 4 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 6 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 3 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> fine-tuning from 'pretrained/TSM_kinetics_RGB_resnet50_shift8_blockres_avg_segment8_e50.pth'
#### Notice: keys that failed to load: set()
=> New dataset, do not load fc weights
video number:3570
video number:1530
group: first_conv_weight has 1 params, lr_mult: 1, decay_mult: 1
group: first_conv_bias has 0 params, lr_mult: 2, decay_mult: 0
group: normal_weight has 52 params, lr_mult: 1, decay_mult: 1
group: normal_bias has 0 params, lr_mult: 2, decay_mult: 0
group: BN scale/shift has 2 params, lr_mult: 1, decay_mult: 0
group: custom_ops has 0 params, lr_mult: 1, decay_mult: 1
group: lr5_weight has 1 params, lr_mult: 5, decay_mult: 1
group: lr10_bias has 1 params, lr_mult: 10, decay_mult: 0
Freezing BatchNorm2D except the first one.
Epoch: [0][0/55], lr: 0.00100	Time 79.688 (79.688)	Data 8.409 (8.409)	Loss 3.9298 (3.9298)	Prec@1 0.000 (0.000)	Prec@5 10.938 (10.938)
Epoch: [0][20/55], lr: 0.00100	Time 1.633 (5.464)	Data 0.000 (0.401)	Loss 3.3601 (3.7404)	Prec@1 32.812 (14.658)	Prec@5 51.562 (30.357)
Epoch: [0][40/55], lr: 0.00100	Time 1.704 (3.615)	Data 0.000 (0.205)	Loss 1.9376 (3.1638)	Prec@1 40.625 (27.248)	Prec@5 81.250 (49.123)
Test: [0/24]	Time 16.119 (16.119)	Loss 1.7900 (1.7900)	Prec@1 50.000 (50.000)	Prec@5 84.375 (84.375)
Test: [20/24]	Time 0.498 (1.235)	Loss 2.2161 (1.6389)	Prec@1 45.312 (53.795)	Prec@5 75.000 (83.854)
Testing Results: Prec@1 53.856 Prec@5 84.444 Loss 1.62245
Best Prec@1: 53.856

Freezing BatchNorm2D except the first one.
Epoch: [1][0/55], lr: 0.00100	Time 15.417 (15.417)	Data 11.488 (11.488)	Loss 1.7262 (1.7262)	Prec@1 56.250 (56.250)	Prec@5 79.688 (79.688)
Epoch: [1][20/55], lr: 0.00100	Time 1.709 (2.337)	Data 0.000 (0.547)	Loss 1.2827 (1.4507)	Prec@1 60.938 (58.631)	Prec@5 92.188 (86.161)
Epoch: [1][40/55], lr: 0.00100	Time 1.743 (2.023)	Data 0.000 (0.280)	Loss 1.1633 (1.3022)	Prec@1 59.375 (62.691)	Prec@5 92.188 (87.843)
Test: [0/24]	Time 9.097 (9.097)	Loss 1.3573 (1.3573)	Prec@1 62.500 (62.500)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.483 (0.905)	Loss 1.6991 (1.1594)	Prec@1 54.688 (66.220)	Prec@5 89.062 (90.997)
Testing Results: Prec@1 66.667 Prec@5 91.307 Loss 1.13885
Best Prec@1: 66.667

Freezing BatchNorm2D except the first one.
Epoch: [2][0/55], lr: 0.00100	Time 13.845 (13.845)	Data 12.190 (12.190)	Loss 0.6924 (0.6924)	Prec@1 76.562 (76.562)	Prec@5 100.000 (100.000)
Epoch: [2][20/55], lr: 0.00100	Time 1.723 (2.273)	Data 0.000 (0.581)	Loss 0.8781 (0.9836)	Prec@1 79.688 (72.247)	Prec@5 92.188 (91.890)
Epoch: [2][40/55], lr: 0.00100	Time 1.707 (1.986)	Data 0.000 (0.298)	Loss 1.1928 (1.0284)	Prec@1 71.875 (70.541)	Prec@5 89.062 (91.654)
Test: [0/24]	Time 9.509 (9.509)	Loss 1.2716 (1.2716)	Prec@1 68.750 (68.750)	Prec@5 87.500 (87.500)
Test: [20/24]	Time 0.479 (0.931)	Loss 1.6477 (1.1146)	Prec@1 57.812 (67.932)	Prec@5 89.062 (92.560)
Testing Results: Prec@1 68.105 Prec@5 92.549 Loss 1.10874
Best Prec@1: 68.105

Freezing BatchNorm2D except the first one.
Epoch: [3][0/55], lr: 0.00100	Time 19.689 (19.689)	Data 17.954 (17.954)	Loss 0.8429 (0.8429)	Prec@1 75.000 (75.000)	Prec@5 92.188 (92.188)
Epoch: [3][20/55], lr: 0.00100	Time 1.694 (2.543)	Data 0.000 (0.855)	Loss 0.9148 (0.8766)	Prec@1 68.750 (75.818)	Prec@5 95.312 (93.527)
Epoch: [3][40/55], lr: 0.00100	Time 1.633 (2.126)	Data 0.000 (0.438)	Loss 0.9320 (0.8719)	Prec@1 65.625 (74.924)	Prec@5 92.188 (93.788)
Test: [0/24]	Time 10.086 (10.086)	Loss 1.2668 (1.2668)	Prec@1 67.188 (67.188)	Prec@5 90.625 (90.625)
Test: [20/24]	Time 0.476 (0.943)	Loss 1.7848 (1.1005)	Prec@1 59.375 (68.006)	Prec@5 81.250 (91.964)
Testing Results: Prec@1 67.778 Prec@5 92.288 Loss 1.08904
Best Prec@1: 68.105

Freezing BatchNorm2D except the first one.
Epoch: [4][0/55], lr: 0.00100	Time 11.377 (11.377)	Data 9.661 (9.661)	Loss 0.7990 (0.7990)	Prec@1 78.125 (78.125)	Prec@5 93.750 (93.750)
Epoch: [4][20/55], lr: 0.00100	Time 1.716 (2.191)	Data 0.000 (0.498)	Loss 0.6333 (0.7199)	Prec@1 78.125 (77.083)	Prec@5 95.312 (95.610)
Epoch: [4][40/55], lr: 0.00100	Time 1.710 (1.949)	Data 0.000 (0.255)	Loss 1.1465 (0.7566)	Prec@1 64.062 (76.296)	Prec@5 90.625 (95.236)
Test: [0/24]	Time 9.407 (9.407)	Loss 1.2999 (1.2999)	Prec@1 62.500 (62.500)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.481 (0.918)	Loss 1.4862 (1.0665)	Prec@1 62.500 (69.345)	Prec@5 87.500 (92.336)
Testing Results: Prec@1 69.346 Prec@5 92.353 Loss 1.06235
Best Prec@1: 69.346

Freezing BatchNorm2D except the first one.
Epoch: [5][0/55], lr: 0.00100	Time 14.162 (14.162)	Data 12.498 (12.498)	Loss 0.6280 (0.6280)	Prec@1 82.812 (82.812)	Prec@5 96.875 (96.875)
Epoch: [5][20/55], lr: 0.00100	Time 1.750 (2.292)	Data 0.000 (0.595)	Loss 0.8713 (0.7613)	Prec@1 71.875 (75.074)	Prec@5 95.312 (96.131)
Epoch: [5][40/55], lr: 0.00100	Time 1.647 (2.004)	Data 0.000 (0.305)	Loss 0.5132 (0.7228)	Prec@1 85.938 (77.134)	Prec@5 98.438 (95.922)
Test: [0/24]	Time 9.242 (9.242)	Loss 1.2654 (1.2654)	Prec@1 71.875 (71.875)	Prec@5 89.062 (89.062)
Test: [20/24]	Time 0.478 (0.914)	Loss 1.8924 (1.1337)	Prec@1 60.938 (68.229)	Prec@5 84.375 (92.485)
Testing Results: Prec@1 68.235 Prec@5 92.418 Loss 1.12808
Best Prec@1: 69.346

Freezing BatchNorm2D except the first one.
Epoch: [6][0/55], lr: 0.00100	Time 12.226 (12.226)	Data 10.505 (10.505)	Loss 0.7318 (0.7318)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Epoch: [6][20/55], lr: 0.00100	Time 1.717 (2.203)	Data 0.000 (0.501)	Loss 0.8900 (0.7051)	Prec@1 70.312 (78.795)	Prec@5 95.312 (95.833)
Epoch: [6][40/55], lr: 0.00100	Time 1.691 (1.956)	Data 0.000 (0.256)	Loss 0.6229 (0.6992)	Prec@1 82.812 (79.002)	Prec@5 96.875 (95.922)
Test: [0/24]	Time 10.098 (10.098)	Loss 1.3019 (1.3019)	Prec@1 68.750 (68.750)	Prec@5 90.625 (90.625)
Test: [20/24]	Time 0.502 (0.947)	Loss 1.7600 (1.0687)	Prec@1 53.125 (69.643)	Prec@5 89.062 (92.411)
Testing Results: Prec@1 69.608 Prec@5 92.484 Loss 1.06642
Best Prec@1: 69.608

Freezing BatchNorm2D except the first one.
Epoch: [7][0/55], lr: 0.00100	Time 11.104 (11.104)	Data 9.409 (9.409)	Loss 0.6974 (0.6974)	Prec@1 79.688 (79.688)	Prec@5 93.750 (93.750)
Epoch: [7][20/55], lr: 0.00100	Time 1.710 (2.156)	Data 0.000 (0.448)	Loss 0.4630 (0.5936)	Prec@1 81.250 (81.548)	Prec@5 98.438 (96.057)
Epoch: [7][40/55], lr: 0.00100	Time 1.635 (1.926)	Data 0.000 (0.230)	Loss 0.6849 (0.6474)	Prec@1 78.125 (79.916)	Prec@5 93.750 (95.808)
Test: [0/24]	Time 9.422 (9.422)	Loss 1.3240 (1.3240)	Prec@1 65.625 (65.625)	Prec@5 87.500 (87.500)
Test: [20/24]	Time 0.479 (0.934)	Loss 1.7172 (1.1246)	Prec@1 59.375 (68.824)	Prec@5 87.500 (92.113)
Testing Results: Prec@1 69.020 Prec@5 91.961 Loss 1.12476
Best Prec@1: 69.608

Freezing BatchNorm2D except the first one.
Epoch: [8][0/55], lr: 0.00100	Time 11.163 (11.163)	Data 9.432 (9.432)	Loss 0.4332 (0.4332)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Epoch: [8][20/55], lr: 0.00100	Time 1.700 (2.155)	Data 0.000 (0.449)	Loss 0.6700 (0.5967)	Prec@1 81.250 (82.366)	Prec@5 95.312 (96.429)
Epoch: [8][40/55], lr: 0.00100	Time 1.673 (1.929)	Data 0.000 (0.230)	Loss 0.5569 (0.6153)	Prec@1 84.375 (81.555)	Prec@5 95.312 (96.532)
Test: [0/24]	Time 8.677 (8.677)	Loss 1.3112 (1.3112)	Prec@1 71.875 (71.875)	Prec@5 90.625 (90.625)
Test: [20/24]	Time 0.479 (0.963)	Loss 1.8111 (1.1362)	Prec@1 60.938 (69.866)	Prec@5 90.625 (92.708)
Testing Results: Prec@1 69.804 Prec@5 93.007 Loss 1.12874
Best Prec@1: 69.804

Freezing BatchNorm2D except the first one.
Epoch: [9][0/55], lr: 0.00100	Time 12.194 (12.194)	Data 10.506 (10.506)	Loss 0.7282 (0.7282)	Prec@1 81.250 (81.250)	Prec@5 95.312 (95.312)
Epoch: [9][20/55], lr: 0.00100	Time 1.725 (2.204)	Data 0.000 (0.501)	Loss 0.5803 (0.5315)	Prec@1 87.500 (83.854)	Prec@5 92.188 (97.024)
Epoch: [9][40/55], lr: 0.00100	Time 1.699 (1.956)	Data 0.000 (0.256)	Loss 0.5386 (0.5349)	Prec@1 82.812 (83.270)	Prec@5 96.875 (97.447)
Test: [0/24]	Time 9.100 (9.100)	Loss 1.2325 (1.2325)	Prec@1 70.312 (70.312)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.482 (0.907)	Loss 1.9096 (1.1840)	Prec@1 59.375 (70.982)	Prec@5 87.500 (92.336)
Testing Results: Prec@1 70.784 Prec@5 92.353 Loss 1.16813
Best Prec@1: 70.784

Freezing BatchNorm2D except the first one.
Epoch: [10][0/55], lr: 0.00010	Time 11.531 (11.531)	Data 9.788 (9.788)	Loss 0.7663 (0.7663)	Prec@1 76.562 (76.562)	Prec@5 93.750 (93.750)
Epoch: [10][20/55], lr: 0.00010	Time 1.707 (2.154)	Data 0.000 (0.466)	Loss 0.5106 (0.4863)	Prec@1 81.250 (85.342)	Prec@5 98.438 (97.247)
Epoch: [10][40/55], lr: 0.00010	Time 1.709 (1.934)	Data 0.000 (0.239)	Loss 0.5927 (0.4435)	Prec@1 81.250 (87.005)	Prec@5 95.312 (97.752)
Test: [0/24]	Time 8.594 (8.594)	Loss 1.3250 (1.3250)	Prec@1 71.875 (71.875)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.479 (0.920)	Loss 1.6967 (1.0635)	Prec@1 64.062 (71.577)	Prec@5 90.625 (93.973)
Testing Results: Prec@1 71.307 Prec@5 93.791 Loss 1.06114
Best Prec@1: 71.307

Freezing BatchNorm2D except the first one.
Epoch: [11][0/55], lr: 0.00010	Time 12.177 (12.177)	Data 10.464 (10.464)	Loss 0.3311 (0.3311)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Epoch: [11][20/55], lr: 0.00010	Time 1.709 (2.199)	Data 0.000 (0.499)	Loss 0.5803 (0.3774)	Prec@1 84.375 (88.393)	Prec@5 93.750 (97.842)
Epoch: [11][40/55], lr: 0.00010	Time 1.698 (1.951)	Data 0.000 (0.255)	Loss 0.4375 (0.3768)	Prec@1 82.812 (88.605)	Prec@5 96.875 (98.133)
Test: [0/24]	Time 7.076 (7.076)	Loss 1.4190 (1.4190)	Prec@1 70.312 (70.312)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.479 (0.886)	Loss 1.7781 (1.0993)	Prec@1 65.625 (71.503)	Prec@5 89.062 (94.196)
Testing Results: Prec@1 71.176 Prec@5 94.118 Loss 1.09526
Best Prec@1: 71.307

Freezing BatchNorm2D except the first one.
Epoch: [12][0/55], lr: 0.00010	Time 9.993 (9.993)	Data 8.252 (8.252)	Loss 0.2685 (0.2685)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Epoch: [12][20/55], lr: 0.00010	Time 1.627 (2.075)	Data 0.000 (0.393)	Loss 0.3668 (0.4073)	Prec@1 89.062 (87.946)	Prec@5 100.000 (98.214)
Epoch: [12][40/55], lr: 0.00010	Time 1.700 (1.887)	Data 0.000 (0.201)	Loss 0.3964 (0.3973)	Prec@1 85.938 (88.453)	Prec@5 98.438 (98.209)
Test: [0/24]	Time 7.663 (7.663)	Loss 1.4022 (1.4022)	Prec@1 68.750 (68.750)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.482 (0.857)	Loss 1.8098 (1.1116)	Prec@1 62.500 (71.801)	Prec@5 89.062 (93.899)
Testing Results: Prec@1 71.569 Prec@5 93.856 Loss 1.10738
Best Prec@1: 71.569

Freezing BatchNorm2D except the first one.
Epoch: [13][0/55], lr: 0.00010	Time 10.515 (10.515)	Data 8.785 (8.785)	Loss 0.5037 (0.5037)	Prec@1 85.938 (85.938)	Prec@5 95.312 (95.312)
Epoch: [13][20/55], lr: 0.00010	Time 1.699 (2.093)	Data 0.000 (0.419)	Loss 0.2275 (0.3350)	Prec@1 92.188 (89.435)	Prec@5 100.000 (98.586)
Epoch: [13][40/55], lr: 0.00010	Time 1.701 (1.895)	Data 0.000 (0.214)	Loss 0.3158 (0.3532)	Prec@1 92.188 (89.024)	Prec@5 100.000 (98.514)
Test: [0/24]	Time 9.349 (9.349)	Loss 1.4099 (1.4099)	Prec@1 71.875 (71.875)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.492 (0.913)	Loss 1.8266 (1.1210)	Prec@1 64.062 (72.024)	Prec@5 89.062 (93.899)
Testing Results: Prec@1 71.765 Prec@5 93.922 Loss 1.11479
Best Prec@1: 71.765

Freezing BatchNorm2D except the first one.
Epoch: [14][0/55], lr: 0.00010	Time 12.195 (12.195)	Data 10.540 (10.540)	Loss 0.2161 (0.2161)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Epoch: [14][20/55], lr: 0.00010	Time 1.633 (2.181)	Data 0.000 (0.502)	Loss 0.4361 (0.3538)	Prec@1 87.500 (88.690)	Prec@5 98.438 (99.033)
Epoch: [14][40/55], lr: 0.00010	Time 1.723 (1.942)	Data 0.000 (0.257)	Loss 0.4569 (0.3680)	Prec@1 89.062 (88.567)	Prec@5 96.875 (98.552)
Test: [0/24]	Time 7.909 (7.909)	Loss 1.4666 (1.4666)	Prec@1 70.312 (70.312)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.486 (0.906)	Loss 1.8781 (1.1055)	Prec@1 64.062 (70.908)	Prec@5 89.062 (93.378)
Testing Results: Prec@1 70.915 Prec@5 93.333 Loss 1.10153
Best Prec@1: 71.765

Freezing BatchNorm2D except the first one.
Epoch: [15][0/55], lr: 0.00010	Time 10.578 (10.578)	Data 8.797 (8.797)	Loss 0.3928 (0.3928)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Epoch: [15][20/55], lr: 0.00010	Time 1.664 (2.118)	Data 0.000 (0.419)	Loss 0.4298 (0.3612)	Prec@1 90.625 (88.988)	Prec@5 98.438 (98.065)
Epoch: [15][40/55], lr: 0.00010	Time 1.704 (1.908)	Data 0.000 (0.215)	Loss 0.4566 (0.3550)	Prec@1 87.500 (89.253)	Prec@5 96.875 (98.361)
Test: [0/24]	Time 9.162 (9.162)	Loss 1.4784 (1.4784)	Prec@1 71.875 (71.875)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.475 (0.936)	Loss 1.8998 (1.1341)	Prec@1 64.062 (71.429)	Prec@5 89.062 (94.122)
Testing Results: Prec@1 71.438 Prec@5 94.183 Loss 1.13116
Best Prec@1: 71.765

Freezing BatchNorm2D except the first one.
Epoch: [16][0/55], lr: 0.00010	Time 11.355 (11.355)	Data 9.624 (9.624)	Loss 0.2871 (0.2871)	Prec@1 92.188 (92.188)	Prec@5 96.875 (96.875)
Epoch: [16][20/55], lr: 0.00010	Time 1.704 (2.154)	Data 0.001 (0.459)	Loss 0.3455 (0.3761)	Prec@1 89.062 (88.765)	Prec@5 100.000 (98.438)
Epoch: [16][40/55], lr: 0.00010	Time 1.628 (1.932)	Data 0.000 (0.235)	Loss 0.2361 (0.3578)	Prec@1 93.750 (89.139)	Prec@5 100.000 (98.819)
Test: [0/24]	Time 7.223 (7.223)	Loss 1.4558 (1.4558)	Prec@1 70.312 (70.312)	Prec@5 93.750 (93.750)
Test: [20/24]	Time 0.485 (0.879)	Loss 1.8641 (1.1281)	Prec@1 62.500 (70.610)	Prec@5 89.062 (94.271)
Testing Results: Prec@1 70.523 Prec@5 94.314 Loss 1.12422
Best Prec@1: 71.765

Freezing BatchNorm2D except the first one.
Epoch: [17][0/55], lr: 0.00010	Time 10.884 (10.884)	Data 9.199 (9.199)	Loss 0.3994 (0.3994)	Prec@1 84.375 (84.375)	Prec@5 96.875 (96.875)
Epoch: [17][20/55], lr: 0.00010	Time 1.645 (2.118)	Data 0.000 (0.438)	Loss 0.3976 (0.3409)	Prec@1 89.062 (89.509)	Prec@5 98.438 (98.884)
Epoch: [17][40/55], lr: 0.00010	Time 1.706 (1.907)	Data 0.000 (0.225)	Loss 0.1402 (0.3420)	Prec@1 96.875 (89.139)	Prec@5 100.000 (98.742)
Test: [0/24]	Time 9.395 (9.395)	Loss 1.4302 (1.4302)	Prec@1 70.312 (70.312)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.479 (0.924)	Loss 1.8271 (1.1339)	Prec@1 67.188 (71.577)	Prec@5 90.625 (93.750)
Testing Results: Prec@1 71.569 Prec@5 93.725 Loss 1.12811
Best Prec@1: 71.765

Freezing BatchNorm2D except the first one.
Epoch: [18][0/55], lr: 0.00010	Time 11.145 (11.145)	Data 9.421 (9.421)	Loss 0.3728 (0.3728)	Prec@1 85.938 (85.938)	Prec@5 96.875 (96.875)
Epoch: [18][20/55], lr: 0.00010	Time 1.642 (2.148)	Data 0.000 (0.449)	Loss 0.3213 (0.3785)	Prec@1 87.500 (87.500)	Prec@5 100.000 (98.363)
Epoch: [18][40/55], lr: 0.00010	Time 1.698 (1.921)	Data 0.000 (0.230)	Loss 0.3928 (0.3580)	Prec@1 87.500 (88.605)	Prec@5 96.875 (98.552)
Test: [0/24]	Time 9.543 (9.543)	Loss 1.4590 (1.4590)	Prec@1 68.750 (68.750)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.485 (0.925)	Loss 1.8433 (1.1491)	Prec@1 62.500 (71.577)	Prec@5 89.062 (93.824)
Testing Results: Prec@1 71.307 Prec@5 93.725 Loss 1.15051
Best Prec@1: 71.765

Freezing BatchNorm2D except the first one.
Epoch: [19][0/55], lr: 0.00010	Time 8.966 (8.966)	Data 7.231 (7.231)	Loss 0.4204 (0.4204)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Epoch: [19][20/55], lr: 0.00010	Time 1.698 (2.039)	Data 0.000 (0.345)	Loss 0.5240 (0.3685)	Prec@1 84.375 (88.542)	Prec@5 93.750 (98.512)
Epoch: [19][40/55], lr: 0.00010	Time 1.695 (1.871)	Data 0.000 (0.177)	Loss 0.2383 (0.3744)	Prec@1 90.625 (88.643)	Prec@5 100.000 (98.285)
Test: [0/24]	Time 8.207 (8.207)	Loss 1.4683 (1.4683)	Prec@1 70.312 (70.312)	Prec@5 93.750 (93.750)
Test: [20/24]	Time 0.504 (0.876)	Loss 1.8768 (1.1419)	Prec@1 62.500 (71.503)	Prec@5 90.625 (94.122)
Testing Results: Prec@1 71.503 Prec@5 94.052 Loss 1.14134
Best Prec@1: 71.765

Freezing BatchNorm2D except the first one.
Epoch: [20][0/55], lr: 0.00001	Time 9.132 (9.132)	Data 7.433 (7.433)	Loss 0.2656 (0.2656)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Epoch: [20][20/55], lr: 0.00001	Time 1.716 (2.048)	Data 0.000 (0.354)	Loss 0.3504 (0.3323)	Prec@1 89.062 (90.104)	Prec@5 98.438 (98.363)
Epoch: [20][40/55], lr: 0.00001	Time 1.718 (1.871)	Data 0.000 (0.182)	Loss 0.5793 (0.3390)	Prec@1 84.375 (89.825)	Prec@5 96.875 (98.323)
Test: [0/24]	Time 8.784 (8.784)	Loss 1.4576 (1.4576)	Prec@1 71.875 (71.875)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.478 (0.941)	Loss 1.8682 (1.1350)	Prec@1 64.062 (71.354)	Prec@5 89.062 (93.824)
Testing Results: Prec@1 71.373 Prec@5 93.725 Loss 1.13535
Best Prec@1: 71.765

Freezing BatchNorm2D except the first one.
Epoch: [21][0/55], lr: 0.00001	Time 8.722 (8.722)	Data 6.978 (6.978)	Loss 0.2013 (0.2013)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Epoch: [21][20/55], lr: 0.00001	Time 1.691 (2.084)	Data 0.000 (0.390)	Loss 0.4557 (0.3144)	Prec@1 85.938 (90.104)	Prec@5 96.875 (98.586)
Epoch: [21][40/55], lr: 0.00001	Time 1.717 (1.888)	Data 0.000 (0.200)	Loss 0.1504 (0.3299)	Prec@1 95.312 (89.329)	Prec@5 100.000 (98.742)
Test: [0/24]	Time 9.289 (9.289)	Loss 1.4691 (1.4691)	Prec@1 70.312 (70.312)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.487 (0.919)	Loss 1.8488 (1.1362)	Prec@1 64.062 (71.503)	Prec@5 89.062 (94.048)
Testing Results: Prec@1 71.373 Prec@5 93.987 Loss 1.13405
Best Prec@1: 71.765

Freezing BatchNorm2D except the first one.
Epoch: [22][0/55], lr: 0.00001	Time 11.400 (11.400)	Data 9.643 (9.643)	Loss 0.3901 (0.3901)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Epoch: [22][20/55], lr: 0.00001	Time 1.724 (2.153)	Data 0.000 (0.459)	Loss 0.1652 (0.3053)	Prec@1 95.312 (90.551)	Prec@5 100.000 (98.586)
Epoch: [22][40/55], lr: 0.00001	Time 1.626 (1.922)	Data 0.000 (0.235)	Loss 0.4124 (0.3242)	Prec@1 87.500 (89.787)	Prec@5 96.875 (98.628)
Test: [0/24]	Time 8.189 (8.189)	Loss 1.5053 (1.5053)	Prec@1 70.312 (70.312)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.480 (0.922)	Loss 1.8717 (1.1401)	Prec@1 64.062 (71.429)	Prec@5 89.062 (94.122)
Testing Results: Prec@1 71.438 Prec@5 94.052 Loss 1.13759
Best Prec@1: 71.765

Freezing BatchNorm2D except the first one.
Epoch: [23][0/55], lr: 0.00001	Time 9.561 (9.561)	Data 7.803 (7.803)	Loss 0.1751 (0.1751)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Epoch: [23][20/55], lr: 0.00001	Time 1.700 (2.077)	Data 0.000 (0.372)	Loss 0.2492 (0.3183)	Prec@1 89.062 (90.402)	Prec@5 100.000 (98.512)
Epoch: [23][40/55], lr: 0.00001	Time 1.622 (1.887)	Data 0.000 (0.191)	Loss 0.4331 (0.3110)	Prec@1 90.625 (90.587)	Prec@5 96.875 (98.704)
Test: [0/24]	Time 10.112 (10.112)	Loss 1.4967 (1.4967)	Prec@1 70.312 (70.312)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.480 (0.971)	Loss 1.8686 (1.1445)	Prec@1 64.062 (71.577)	Prec@5 89.062 (94.271)
Testing Results: Prec@1 71.503 Prec@5 94.248 Loss 1.14183
Best Prec@1: 71.765

Freezing BatchNorm2D except the first one.
Epoch: [24][0/55], lr: 0.00001	Time 10.635 (10.635)	Data 8.904 (8.904)	Loss 0.3334 (0.3334)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Epoch: [24][20/55], lr: 0.00001	Time 1.688 (2.114)	Data 0.000 (0.424)	Loss 0.2628 (0.3412)	Prec@1 93.750 (89.286)	Prec@5 98.438 (98.661)
Epoch: [24][40/55], lr: 0.00001	Time 1.698 (1.906)	Data 0.000 (0.217)	Loss 0.2787 (0.3253)	Prec@1 90.625 (89.748)	Prec@5 98.438 (98.819)
Test: [0/24]	Time 8.839 (8.839)	Loss 1.5041 (1.5041)	Prec@1 70.312 (70.312)	Prec@5 92.188 (92.188)
Test: [20/24]	Time 0.489 (0.942)	Loss 1.8659 (1.1422)	Prec@1 64.062 (71.577)	Prec@5 89.062 (94.122)
Testing Results: Prec@1 71.438 Prec@5 94.052 Loss 1.14023
Best Prec@1: 71.765

hmdb51: 51 classes
storing name: TSM_hmdb51_RGB_resnet50_shift8_blockres_avg_segment8_e25

    Initializing TSN with base model: resnet50.
    TSN Configurations:
        input_modality:     RGB
        num_segments:       8
        new_length:         1
        consensus_module:   avg
        dropout_ratio:      0.8
        img_feature_dim:    256
            
=> base model: resnet50
Adding temporal shift...
=> n_segment per stage: [8, 8, 8, 8]
=> Processing stage with 3 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 4 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 6 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 3 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> fine-tuning from 'pretrained/TSM_kinetics_RGB_resnet50_shift8_blockres_avg_segment8_e50.pth'
#### Notice: keys that failed to load: set()
=> New dataset, do not load fc weights
video number:3570
video number:1530
group: first_conv_weight has 1 params, lr_mult: 1, decay_mult: 1
group: first_conv_bias has 0 params, lr_mult: 2, decay_mult: 0
group: normal_weight has 52 params, lr_mult: 1, decay_mult: 1
group: normal_bias has 0 params, lr_mult: 2, decay_mult: 0
group: BN scale/shift has 2 params, lr_mult: 1, decay_mult: 0
group: custom_ops has 0 params, lr_mult: 1, decay_mult: 1
group: lr5_weight has 1 params, lr_mult: 5, decay_mult: 1
group: lr10_bias has 1 params, lr_mult: 10, decay_mult: 0
Freezing BatchNorm2D except the first one.
Epoch: [0][0/55], lr: 0.00100	Time 76.766 (76.766)	Data 5.438 (5.438)	Loss 3.9299 (3.9299)	Prec@1 1.562 (1.562)	Prec@5 14.062 (14.062)
hmdb51: 51 classes
storing name: TSM_hmdb51_RGB_resnet50_shift8_blockres_avg_segment8_e25

    Initializing TSN with base model: resnet50.
    TSN Configurations:
        input_modality:     RGB
        num_segments:       8
        new_length:         1
        consensus_module:   avg
        dropout_ratio:      0.8
        img_feature_dim:    256
            
=> base model: resnet50
Adding temporal shift...
=> n_segment per stage: [8, 8, 8, 8]
=> Processing stage with 3 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 4 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 6 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 3 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> fine-tuning from 'pretrained/TSM_kinetics_RGB_resnet50_shift8_blockres_avg_segment8_e50.pth'
#### Notice: keys that failed to load: set()
=> New dataset, do not load fc weights
video number:3570
video number:1530
group: first_conv_weight has 1 params, lr_mult: 1, decay_mult: 1
group: first_conv_bias has 0 params, lr_mult: 2, decay_mult: 0
group: normal_weight has 52 params, lr_mult: 1, decay_mult: 1
group: normal_bias has 0 params, lr_mult: 2, decay_mult: 0
group: BN scale/shift has 2 params, lr_mult: 1, decay_mult: 0
group: custom_ops has 0 params, lr_mult: 1, decay_mult: 1
group: lr5_weight has 1 params, lr_mult: 5, decay_mult: 1
group: lr10_bias has 1 params, lr_mult: 10, decay_mult: 0
Freezing BatchNorm2D except the first one.
hmdb51: 51 classes
storing name: TSM_hmdb51_RGB_resnet50_shift8_blockres_avg_segment8_e25

    Initializing TSN with base model: resnet50.
    TSN Configurations:
        input_modality:     RGB
        num_segments:       8
        new_length:         1
        consensus_module:   avg
        dropout_ratio:      0.8
        img_feature_dim:    256
            
=> base model: resnet50
Adding temporal shift...
=> n_segment per stage: [8, 8, 8, 8]
=> Processing stage with 3 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 4 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 6 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 3 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> fine-tuning from 'pretrained/TSM_kinetics_RGB_resnet50_shift8_blockres_avg_segment8_e50.pth'
#### Notice: keys that failed to load: set()
=> New dataset, do not load fc weights
video number:3570
video number:1530
group: first_conv_weight has 1 params, lr_mult: 1, decay_mult: 1
group: first_conv_bias has 0 params, lr_mult: 2, decay_mult: 0
group: normal_weight has 52 params, lr_mult: 1, decay_mult: 1
group: normal_bias has 0 params, lr_mult: 2, decay_mult: 0
group: BN scale/shift has 2 params, lr_mult: 1, decay_mult: 0
group: custom_ops has 0 params, lr_mult: 1, decay_mult: 1
group: lr5_weight has 1 params, lr_mult: 5, decay_mult: 1
group: lr10_bias has 1 params, lr_mult: 10, decay_mult: 0
Freezing BatchNorm2D except the first one.
hmdb51: 51 classes
storing name: TSM_hmdb51_RGB_resnet50_shift8_blockres_avg_segment8_e25

    Initializing TSN with base model: resnet50.
    TSN Configurations:
        input_modality:     RGB
        num_segments:       8
        new_length:         1
        consensus_module:   avg
        dropout_ratio:      0.8
        img_feature_dim:    256
            
=> base model: resnet50
Adding temporal shift...
=> n_segment per stage: [8, 8, 8, 8]
=> Processing stage with 3 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 4 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 6 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> Processing stage with 3 blocks residual
=> Using fold div: 8
=> Using fold div: 8
=> Using fold div: 8
=> fine-tuning from 'pretrained/TSM_kinetics_RGB_resnet50_shift8_blockres_avg_segment8_e50.pth'
#### Notice: keys that failed to load: set()
=> New dataset, do not load fc weights
video number:3570
video number:1530
group: first_conv_weight has 1 params, lr_mult: 1, decay_mult: 1
group: first_conv_bias has 0 params, lr_mult: 2, decay_mult: 0
group: normal_weight has 52 params, lr_mult: 1, decay_mult: 1
group: normal_bias has 0 params, lr_mult: 2, decay_mult: 0
group: BN scale/shift has 2 params, lr_mult: 1, decay_mult: 0
group: custom_ops has 0 params, lr_mult: 1, decay_mult: 1
group: lr5_weight has 1 params, lr_mult: 5, decay_mult: 1
group: lr10_bias has 1 params, lr_mult: 10, decay_mult: 0
Freezing BatchNorm2D except the first one.
Epoch: [0][0/111], lr: 0.00100	Time 43.393 (43.393)	Data 4.445 (4.445)	Loss 3.9345 (3.9345)	Prec@1 3.125 (3.125)	Prec@5 3.125 (3.125)
Epoch: [0][20/111], lr: 0.00100	Time 1.606 (3.610)	Data 0.000 (0.212)	Loss 3.5236 (3.7975)	Prec@1 25.000 (10.119)	Prec@5 46.875 (25.298)
Epoch: [0][40/111], lr: 0.00100	Time 1.603 (2.626)	Data 0.000 (0.109)	Loss 1.9694 (3.3012)	Prec@1 53.125 (21.875)	Prec@5 71.875 (42.912)
Epoch: [0][60/111], lr: 0.00100	Time 1.616 (2.290)	Data 0.000 (0.073)	Loss 1.4526 (2.8348)	Prec@1 59.375 (31.301)	Prec@5 93.750 (53.996)
Epoch: [0][80/111], lr: 0.00100	Time 1.598 (2.120)	Data 0.000 (0.055)	Loss 1.3700 (2.5455)	Prec@1 59.375 (37.114)	Prec@5 84.375 (60.648)
Epoch: [0][100/111], lr: 0.00100	Time 1.606 (2.017)	Data 0.000 (0.044)	Loss 1.5267 (2.3214)	Prec@1 62.500 (41.491)	Prec@5 90.625 (65.934)
Test: [0/48]	Time 5.091 (5.091)	Loss 1.4445 (1.4445)	Prec@1 65.625 (65.625)	Prec@5 87.500 (87.500)
Test: [20/48]	Time 0.472 (0.701)	Loss 1.5874 (1.3907)	Prec@1 56.250 (60.119)	Prec@5 75.000 (88.393)
Test: [40/48]	Time 0.471 (0.588)	Loss 1.3178 (1.3807)	Prec@1 62.500 (61.509)	Prec@5 90.625 (88.034)
Testing Results: Prec@1 61.765 Prec@5 88.170 Loss 1.36936
Best Prec@1: 61.765

Freezing BatchNorm2D except the first one.
Epoch: [1][0/111], lr: 0.00100	Time 7.382 (7.382)	Data 5.027 (5.027)	Loss 1.6832 (1.6832)	Prec@1 53.125 (53.125)	Prec@5 78.125 (78.125)
Epoch: [1][20/111], lr: 0.00100	Time 1.615 (1.874)	Data 0.000 (0.240)	Loss 1.2647 (1.2099)	Prec@1 62.500 (63.542)	Prec@5 87.500 (90.179)
Epoch: [1][40/111], lr: 0.00100	Time 1.596 (1.741)	Data 0.000 (0.123)	Loss 1.3262 (1.2030)	Prec@1 59.375 (64.787)	Prec@5 84.375 (89.405)
Epoch: [1][60/111], lr: 0.00100	Time 1.600 (1.694)	Data 0.000 (0.083)	Loss 0.9518 (1.1954)	Prec@1 71.875 (65.215)	Prec@5 90.625 (89.600)
Epoch: [1][80/111], lr: 0.00100	Time 1.599 (1.670)	Data 0.000 (0.062)	Loss 1.2009 (1.1887)	Prec@1 68.750 (65.394)	Prec@5 84.375 (89.198)
Epoch: [1][100/111], lr: 0.00100	Time 1.598 (1.656)	Data 0.000 (0.050)	Loss 1.1023 (1.1753)	Prec@1 56.250 (65.934)	Prec@5 93.750 (89.697)
Test: [0/48]	Time 4.875 (4.875)	Loss 1.6163 (1.6163)	Prec@1 62.500 (62.500)	Prec@5 81.250 (81.250)
Test: [20/48]	Time 0.468 (0.689)	Loss 1.5283 (1.1215)	Prec@1 65.625 (68.304)	Prec@5 84.375 (91.964)
Test: [40/48]	Time 0.470 (0.582)	Loss 1.1282 (1.0873)	Prec@1 71.875 (69.588)	Prec@5 93.750 (92.149)
Testing Results: Prec@1 69.020 Prec@5 91.569 Loss 1.11644
Best Prec@1: 69.020

Freezing BatchNorm2D except the first one.
Epoch: [2][0/111], lr: 0.00100	Time 5.828 (5.828)	Data 4.198 (4.198)	Loss 0.9851 (0.9851)	Prec@1 71.875 (71.875)	Prec@5 96.875 (96.875)
Epoch: [2][20/111], lr: 0.00100	Time 1.598 (1.804)	Data 0.000 (0.200)	Loss 0.8036 (0.9905)	Prec@1 71.875 (70.982)	Prec@5 96.875 (93.304)
Epoch: [2][40/111], lr: 0.00100	Time 1.622 (1.707)	Data 0.000 (0.103)	Loss 1.0369 (0.9851)	Prec@1 68.750 (71.341)	Prec@5 90.625 (92.835)
Epoch: [2][60/111], lr: 0.00100	Time 1.613 (1.675)	Data 0.000 (0.069)	Loss 0.8503 (0.9787)	Prec@1 75.000 (71.158)	Prec@5 93.750 (92.828)
Epoch: [2][80/111], lr: 0.00100	Time 1.598 (1.657)	Data 0.000 (0.052)	Loss 0.7668 (0.9702)	Prec@1 75.000 (71.605)	Prec@5 100.000 (92.824)
Epoch: [2][100/111], lr: 0.00100	Time 1.604 (1.645)	Data 0.000 (0.042)	Loss 0.9180 (0.9936)	Prec@1 68.750 (70.730)	Prec@5 90.625 (92.481)
Test: [0/48]	Time 4.807 (4.807)	Loss 1.3781 (1.3781)	Prec@1 62.500 (62.500)	Prec@5 84.375 (84.375)
Test: [20/48]	Time 0.490 (0.726)	Loss 1.4789 (1.1472)	Prec@1 56.250 (67.560)	Prec@5 87.500 (91.369)
Test: [40/48]	Time 0.468 (0.604)	Loss 1.0589 (1.1165)	Prec@1 68.750 (69.360)	Prec@5 90.625 (91.387)
Testing Results: Prec@1 68.627 Prec@5 91.046 Loss 1.14166
Best Prec@1: 69.020

Freezing BatchNorm2D except the first one.
Epoch: [3][0/111], lr: 0.00100	Time 5.726 (5.726)	Data 4.104 (4.104)	Loss 0.8026 (0.8026)	Prec@1 78.125 (78.125)	Prec@5 96.875 (96.875)
Epoch: [3][20/111], lr: 0.00100	Time 1.598 (1.796)	Data 0.000 (0.196)	Loss 0.9294 (0.8282)	Prec@1 68.750 (74.851)	Prec@5 96.875 (94.345)
Epoch: [3][40/111], lr: 0.00100	Time 1.584 (1.699)	Data 0.000 (0.100)	Loss 0.4900 (0.7913)	Prec@1 84.375 (76.067)	Prec@5 96.875 (94.970)
Epoch: [3][60/111], lr: 0.00100	Time 1.590 (1.667)	Data 0.000 (0.068)	Loss 0.8546 (0.7822)	Prec@1 81.250 (76.537)	Prec@5 96.875 (94.928)
Epoch: [3][80/111], lr: 0.00100	Time 1.590 (1.651)	Data 0.000 (0.051)	Loss 1.5714 (0.8199)	Prec@1 65.625 (75.772)	Prec@5 93.750 (94.522)
Epoch: [3][100/111], lr: 0.00100	Time 1.582 (1.640)	Data 0.000 (0.041)	Loss 0.7080 (0.8064)	Prec@1 75.000 (76.145)	Prec@5 96.875 (94.400)
Test: [0/48]	Time 4.680 (4.680)	Loss 1.7992 (1.7992)	Prec@1 59.375 (59.375)	Prec@5 81.250 (81.250)
Test: [20/48]	Time 0.472 (0.704)	Loss 1.3453 (1.2128)	Prec@1 59.375 (67.113)	Prec@5 87.500 (91.964)
Test: [40/48]	Time 0.470 (0.589)	Loss 1.5602 (1.1508)	Prec@1 62.500 (68.293)	Prec@5 84.375 (91.997)
Testing Results: Prec@1 67.712 Prec@5 92.026 Loss 1.16306
Best Prec@1: 69.020

Freezing BatchNorm2D except the first one.
Epoch: [4][0/111], lr: 0.00100	Time 5.489 (5.489)	Data 3.807 (3.807)	Loss 0.6745 (0.6745)	Prec@1 84.375 (84.375)	Prec@5 96.875 (96.875)
Epoch: [4][20/111], lr: 0.00100	Time 1.619 (1.786)	Data 0.000 (0.181)	Loss 0.7525 (0.7986)	Prec@1 68.750 (74.554)	Prec@5 96.875 (94.940)
Epoch: [4][40/111], lr: 0.00100	Time 1.623 (1.701)	Data 0.000 (0.093)	Loss 0.7144 (0.7659)	Prec@1 84.375 (76.220)	Prec@5 90.625 (94.893)
Epoch: [4][60/111], lr: 0.00100	Time 1.606 (1.668)	Data 0.000 (0.063)	Loss 0.8426 (0.7474)	Prec@1 81.250 (77.459)	Prec@5 93.750 (95.082)
Epoch: [4][80/111], lr: 0.00100	Time 1.592 (1.653)	Data 0.000 (0.047)	Loss 0.4703 (0.7374)	Prec@1 87.500 (77.469)	Prec@5 100.000 (95.370)
Epoch: [4][100/111], lr: 0.00100	Time 1.590 (1.643)	Data 0.000 (0.038)	Loss 1.0007 (0.7403)	Prec@1 75.000 (77.754)	Prec@5 87.500 (95.204)
Test: [0/48]	Time 4.683 (4.683)	Loss 1.7481 (1.7481)	Prec@1 56.250 (56.250)	Prec@5 81.250 (81.250)
Test: [20/48]	Time 0.479 (0.694)	Loss 1.4641 (1.1297)	Prec@1 62.500 (66.964)	Prec@5 87.500 (92.113)
Test: [40/48]	Time 0.467 (0.588)	Loss 1.2347 (1.0897)	Prec@1 65.625 (67.835)	Prec@5 93.750 (92.302)
Testing Results: Prec@1 67.647 Prec@5 91.961 Loss 1.10469
Best Prec@1: 69.020

Freezing BatchNorm2D except the first one.
Epoch: [5][0/111], lr: 0.00100	Time 5.624 (5.624)	Data 3.966 (3.966)	Loss 0.5846 (0.5846)	Prec@1 81.250 (81.250)	Prec@5 96.875 (96.875)
Epoch: [5][20/111], lr: 0.00100	Time 1.599 (1.794)	Data 0.000 (0.189)	Loss 0.4292 (0.6701)	Prec@1 87.500 (80.655)	Prec@5 96.875 (95.536)
Epoch: [5][40/111], lr: 0.00100	Time 1.621 (1.701)	Data 0.000 (0.097)	Loss 0.7063 (0.6544)	Prec@1 75.000 (81.174)	Prec@5 96.875 (95.579)
Epoch: [5][60/111], lr: 0.00100	Time 1.594 (1.669)	Data 0.000 (0.065)	Loss 0.5549 (0.6559)	Prec@1 81.250 (80.482)	Prec@5 93.750 (95.748)
Epoch: [5][80/111], lr: 0.00100	Time 1.589 (1.652)	Data 0.000 (0.049)	Loss 0.6806 (0.6786)	Prec@1 78.125 (79.475)	Prec@5 100.000 (95.370)
Epoch: [5][100/111], lr: 0.00100	Time 1.684 (1.643)	Data 0.000 (0.039)	Loss 0.5859 (0.6885)	Prec@1 87.500 (78.960)	Prec@5 100.000 (95.452)
Test: [0/48]	Time 5.798 (5.798)	Loss 1.6139 (1.6139)	Prec@1 68.750 (68.750)	Prec@5 81.250 (81.250)
Test: [20/48]	Time 0.492 (0.737)	Loss 1.4584 (1.1009)	Prec@1 68.750 (71.875)	Prec@5 84.375 (92.560)
Test: [40/48]	Time 0.470 (0.611)	Loss 1.1830 (1.0649)	Prec@1 65.625 (71.494)	Prec@5 90.625 (92.835)
Testing Results: Prec@1 70.980 Prec@5 92.941 Loss 1.07549
Best Prec@1: 70.980

Freezing BatchNorm2D except the first one.
Epoch: [6][0/111], lr: 0.00100	Time 6.858 (6.858)	Data 5.184 (5.184)	Loss 0.6524 (0.6524)	Prec@1 81.250 (81.250)	Prec@5 96.875 (96.875)
Epoch: [6][20/111], lr: 0.00100	Time 1.610 (1.855)	Data 0.000 (0.247)	Loss 0.4999 (0.6159)	Prec@1 84.375 (80.804)	Prec@5 93.750 (96.875)
Epoch: [6][40/111], lr: 0.00100	Time 1.601 (1.731)	Data 0.000 (0.127)	Loss 1.0760 (0.6424)	Prec@1 78.125 (80.107)	Prec@5 93.750 (96.113)
Epoch: [6][60/111], lr: 0.00100	Time 1.589 (1.690)	Data 0.000 (0.085)	Loss 0.8540 (0.6600)	Prec@1 81.250 (80.430)	Prec@5 90.625 (96.004)
Epoch: [6][80/111], lr: 0.00100	Time 1.601 (1.667)	Data 0.000 (0.064)	Loss 0.9224 (0.6530)	Prec@1 75.000 (80.517)	Prec@5 90.625 (96.296)
Epoch: [6][100/111], lr: 0.00100	Time 1.602 (1.655)	Data 0.000 (0.052)	Loss 0.7637 (0.6517)	Prec@1 81.250 (80.662)	Prec@5 93.750 (96.163)
Test: [0/48]	Time 4.800 (4.800)	Loss 1.7503 (1.7503)	Prec@1 62.500 (62.500)	Prec@5 90.625 (90.625)
Test: [20/48]	Time 0.518 (0.715)	Loss 1.5407 (1.1957)	Prec@1 59.375 (69.048)	Prec@5 84.375 (91.369)
Test: [40/48]	Time 0.470 (0.598)	Loss 1.1093 (1.1294)	Prec@1 68.750 (70.884)	Prec@5 93.750 (91.768)
Testing Results: Prec@1 70.588 Prec@5 91.699 Loss 1.14242
Best Prec@1: 70.980

Freezing BatchNorm2D except the first one.
Epoch: [7][0/111], lr: 0.00100	Time 6.017 (6.017)	Data 4.387 (4.387)	Loss 0.3583 (0.3583)	Prec@1 90.625 (90.625)	Prec@5 96.875 (96.875)
Epoch: [7][20/111], lr: 0.00100	Time 1.654 (1.816)	Data 0.000 (0.209)	Loss 0.8337 (0.5572)	Prec@1 75.000 (83.333)	Prec@5 90.625 (96.280)
Epoch: [7][40/111], lr: 0.00100	Time 1.616 (1.714)	Data 0.000 (0.107)	Loss 0.5429 (0.5536)	Prec@1 90.625 (83.003)	Prec@5 100.000 (96.875)
Epoch: [7][60/111], lr: 0.00100	Time 1.590 (1.679)	Data 0.000 (0.072)	Loss 0.2107 (0.5704)	Prec@1 96.875 (82.684)	Prec@5 100.000 (96.516)
Epoch: [7][80/111], lr: 0.00100	Time 1.586 (1.661)	Data 0.001 (0.054)	Loss 0.3232 (0.5891)	Prec@1 93.750 (82.330)	Prec@5 100.000 (96.219)
Epoch: [7][100/111], lr: 0.00100	Time 1.591 (1.649)	Data 0.000 (0.044)	Loss 0.3022 (0.5849)	Prec@1 90.625 (82.395)	Prec@5 100.000 (96.411)
Test: [0/48]	Time 6.263 (6.263)	Loss 1.8714 (1.8714)	Prec@1 59.375 (59.375)	Prec@5 84.375 (84.375)
Test: [20/48]	Time 0.490 (0.762)	Loss 1.6940 (1.2183)	Prec@1 65.625 (70.685)	Prec@5 84.375 (92.411)
Test: [40/48]	Time 0.480 (0.621)	Loss 1.2951 (1.1312)	Prec@1 68.750 (71.418)	Prec@5 90.625 (92.835)
Testing Results: Prec@1 71.111 Prec@5 93.007 Loss 1.13405
Best Prec@1: 71.111

Freezing BatchNorm2D except the first one.
Epoch: [8][0/111], lr: 0.00100	Time 6.580 (6.580)	Data 4.937 (4.937)	Loss 0.5043 (0.5043)	Prec@1 87.500 (87.500)	Prec@5 93.750 (93.750)
Epoch: [8][20/111], lr: 0.00100	Time 1.588 (1.848)	Data 0.000 (0.235)	Loss 0.3102 (0.4571)	Prec@1 90.625 (86.310)	Prec@5 96.875 (98.214)
Epoch: [8][40/111], lr: 0.00100	Time 1.620 (1.731)	Data 0.000 (0.121)	Loss 0.4327 (0.4649)	Prec@1 78.125 (85.823)	Prec@5 100.000 (97.866)
Epoch: [8][60/111], lr: 0.00100	Time 1.599 (1.689)	Data 0.000 (0.081)	Loss 0.7567 (0.4923)	Prec@1 78.125 (85.143)	Prec@5 96.875 (97.592)
Epoch: [8][80/111], lr: 0.00100	Time 1.595 (1.670)	Data 0.000 (0.061)	Loss 0.6769 (0.5070)	Prec@1 78.125 (84.452)	Prec@5 93.750 (97.338)
Epoch: [8][100/111], lr: 0.00100	Time 1.603 (1.657)	Data 0.000 (0.049)	Loss 0.6502 (0.5124)	Prec@1 84.375 (84.653)	Prec@5 96.875 (97.401)
Test: [0/48]	Time 5.552 (5.552)	Loss 2.4822 (2.4822)	Prec@1 46.875 (46.875)	Prec@5 78.125 (78.125)
Test: [20/48]	Time 0.505 (0.732)	Loss 1.6105 (1.2474)	Prec@1 59.375 (67.262)	Prec@5 87.500 (91.964)
Test: [40/48]	Time 0.470 (0.607)	Loss 1.4159 (1.2337)	Prec@1 65.625 (69.207)	Prec@5 93.750 (91.997)
Testing Results: Prec@1 69.085 Prec@5 92.026 Loss 1.24035
Best Prec@1: 71.111

Freezing BatchNorm2D except the first one.
Epoch: [9][0/111], lr: 0.00100	Time 6.598 (6.598)	Data 4.924 (4.924)	Loss 0.7866 (0.7866)	Prec@1 78.125 (78.125)	Prec@5 93.750 (93.750)
Epoch: [9][20/111], lr: 0.00100	Time 1.593 (1.848)	Data 0.000 (0.235)	Loss 0.5383 (0.5127)	Prec@1 81.250 (84.673)	Prec@5 96.875 (98.363)
Epoch: [9][40/111], lr: 0.00100	Time 1.595 (1.729)	Data 0.000 (0.120)	Loss 0.5469 (0.5129)	Prec@1 90.625 (83.994)	Prec@5 96.875 (97.713)
Epoch: [9][60/111], lr: 0.00100	Time 1.593 (1.690)	Data 0.000 (0.081)	Loss 0.5920 (0.4826)	Prec@1 81.250 (84.529)	Prec@5 93.750 (97.900)
Epoch: [9][80/111], lr: 0.00100	Time 1.605 (1.670)	Data 0.000 (0.061)	Loss 0.6451 (0.5139)	Prec@1 81.250 (84.066)	Prec@5 100.000 (97.647)
Epoch: [9][100/111], lr: 0.00100	Time 1.605 (1.656)	Data 0.000 (0.049)	Loss 0.5868 (0.5242)	Prec@1 81.250 (83.818)	Prec@5 93.750 (97.525)
Test: [0/48]	Time 5.302 (5.302)	Loss 1.7772 (1.7772)	Prec@1 62.500 (62.500)	Prec@5 87.500 (87.500)
Test: [20/48]	Time 0.470 (0.710)	Loss 1.6374 (1.1375)	Prec@1 59.375 (68.601)	Prec@5 87.500 (93.452)
Test: [40/48]	Time 0.468 (0.593)	Loss 1.2784 (1.1361)	Prec@1 65.625 (69.055)	Prec@5 93.750 (93.216)
Testing Results: Prec@1 68.693 Prec@5 93.072 Loss 1.16125
Best Prec@1: 71.111

Freezing BatchNorm2D except the first one.
Epoch: [10][0/111], lr: 0.00010	Time 6.308 (6.308)	Data 4.666 (4.666)	Loss 0.5384 (0.5384)	Prec@1 81.250 (81.250)	Prec@5 96.875 (96.875)
Epoch: [10][20/111], lr: 0.00010	Time 1.586 (1.828)	Data 0.000 (0.222)	Loss 0.3660 (0.3776)	Prec@1 90.625 (90.179)	Prec@5 96.875 (98.363)
Epoch: [10][40/111], lr: 0.00010	Time 1.652 (1.721)	Data 0.000 (0.114)	Loss 0.3969 (0.3798)	Prec@1 90.625 (89.405)	Prec@5 93.750 (98.476)
Epoch: [10][60/111], lr: 0.00010	Time 1.598 (1.682)	Data 0.000 (0.077)	Loss 0.3269 (0.3903)	Prec@1 90.625 (88.627)	Prec@5 96.875 (98.053)
Epoch: [10][80/111], lr: 0.00010	Time 1.605 (1.662)	Data 0.000 (0.058)	Loss 0.4270 (0.3771)	Prec@1 84.375 (88.966)	Prec@5 93.750 (98.032)
Epoch: [10][100/111], lr: 0.00010	Time 1.600 (1.650)	Data 0.000 (0.046)	Loss 0.5222 (0.3715)	Prec@1 84.375 (89.140)	Prec@5 96.875 (98.051)
Test: [0/48]	Time 4.661 (4.661)	Loss 1.9309 (1.9309)	Prec@1 62.500 (62.500)	Prec@5 84.375 (84.375)
Test: [20/48]	Time 0.490 (0.707)	Loss 1.8544 (1.1025)	Prec@1 62.500 (70.982)	Prec@5 87.500 (94.196)
Test: [40/48]	Time 0.470 (0.594)	Loss 1.2528 (1.0656)	Prec@1 71.875 (72.256)	Prec@5 93.750 (93.598)
Testing Results: Prec@1 71.765 Prec@5 93.399 Loss 1.08519
Best Prec@1: 71.765

Freezing BatchNorm2D except the first one.
Epoch: [11][0/111], lr: 0.00010	Time 6.901 (6.901)	Data 5.271 (5.271)	Loss 0.2170 (0.2170)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Epoch: [11][20/111], lr: 0.00010	Time 1.605 (1.862)	Data 0.000 (0.251)	Loss 0.4986 (0.3020)	Prec@1 78.125 (90.476)	Prec@5 100.000 (98.363)
Epoch: [11][40/111], lr: 0.00010	Time 1.591 (1.733)	Data 0.000 (0.129)	Loss 0.1306 (0.3027)	Prec@1 93.750 (89.939)	Prec@5 100.000 (98.857)
Epoch: [11][60/111], lr: 0.00010	Time 1.618 (1.690)	Data 0.000 (0.087)	Loss 0.5219 (0.3018)	Prec@1 84.375 (90.164)	Prec@5 96.875 (98.719)
Epoch: [11][80/111], lr: 0.00010	Time 1.597 (1.670)	Data 0.000 (0.065)	Loss 0.3670 (0.3101)	Prec@1 87.500 (90.123)	Prec@5 100.000 (98.534)
Epoch: [11][100/111], lr: 0.00010	Time 1.608 (1.657)	Data 0.000 (0.052)	Loss 0.0919 (0.3152)	Prec@1 96.875 (89.944)	Prec@5 100.000 (98.515)
Test: [0/48]	Time 4.972 (4.972)	Loss 2.0220 (2.0220)	Prec@1 65.625 (65.625)	Prec@5 84.375 (84.375)
Test: [20/48]	Time 0.467 (0.701)	Loss 2.0339 (1.1702)	Prec@1 56.250 (70.536)	Prec@5 87.500 (93.601)
Test: [40/48]	Time 0.465 (0.588)	Loss 1.1625 (1.1200)	Prec@1 78.125 (72.180)	Prec@5 93.750 (93.979)
Testing Results: Prec@1 71.765 Prec@5 93.922 Loss 1.14509
Best Prec@1: 71.765

Freezing BatchNorm2D except the first one.
Epoch: [12][0/111], lr: 0.00010	Time 6.016 (6.016)	Data 4.385 (4.385)	Loss 0.1723 (0.1723)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Epoch: [12][20/111], lr: 0.00010	Time 1.599 (1.821)	Data 0.000 (0.209)	Loss 0.1531 (0.3047)	Prec@1 96.875 (90.774)	Prec@5 100.000 (98.810)
Epoch: [12][40/111], lr: 0.00010	Time 1.682 (1.716)	Data 0.000 (0.107)	Loss 0.7210 (0.3159)	Prec@1 78.125 (90.549)	Prec@5 90.625 (98.552)
Epoch: [12][60/111], lr: 0.00010	Time 1.599 (1.678)	Data 0.000 (0.072)	Loss 0.4666 (0.3046)	Prec@1 84.375 (90.676)	Prec@5 100.000 (98.873)
Epoch: [12][80/111], lr: 0.00010	Time 1.596 (1.661)	Data 0.000 (0.054)	Loss 0.3086 (0.3008)	Prec@1 90.625 (90.664)	Prec@5 96.875 (98.843)
Epoch: [12][100/111], lr: 0.00010	Time 1.601 (1.648)	Data 0.000 (0.044)	Loss 0.1081 (0.2942)	Prec@1 96.875 (90.749)	Prec@5 100.000 (98.731)
Test: [0/48]	Time 4.874 (4.874)	Loss 2.0504 (2.0504)	Prec@1 59.375 (59.375)	Prec@5 87.500 (87.500)
Test: [20/48]	Time 0.490 (0.697)	Loss 1.9185 (1.1659)	Prec@1 59.375 (70.685)	Prec@5 87.500 (94.345)
Test: [40/48]	Time 0.468 (0.588)	Loss 1.1874 (1.1237)	Prec@1 78.125 (72.180)	Prec@5 93.750 (93.826)
Testing Results: Prec@1 71.830 Prec@5 93.856 Loss 1.15119
Best Prec@1: 71.830

Freezing BatchNorm2D except the first one.
Epoch: [13][0/111], lr: 0.00010	Time 6.116 (6.116)	Data 4.469 (4.469)	Loss 0.5854 (0.5854)	Prec@1 90.625 (90.625)	Prec@5 96.875 (96.875)
Epoch: [13][20/111], lr: 0.00010	Time 1.587 (1.821)	Data 0.000 (0.213)	Loss 0.1182 (0.2605)	Prec@1 96.875 (92.113)	Prec@5 100.000 (99.107)
Epoch: [13][40/111], lr: 0.00010	Time 1.586 (1.713)	Data 0.000 (0.109)	Loss 0.4243 (0.2724)	Prec@1 87.500 (91.616)	Prec@5 100.000 (99.009)
Epoch: [13][60/111], lr: 0.00010	Time 1.633 (1.679)	Data 0.000 (0.073)	Loss 0.1062 (0.2855)	Prec@1 93.750 (91.291)	Prec@5 100.000 (99.027)
Epoch: [13][80/111], lr: 0.00010	Time 1.599 (1.660)	Data 0.000 (0.055)	Loss 0.2146 (0.2779)	Prec@1 93.750 (91.474)	Prec@5 100.000 (99.074)
Epoch: [13][100/111], lr: 0.00010	Time 1.600 (1.648)	Data 0.000 (0.044)	Loss 0.4723 (0.2851)	Prec@1 87.500 (91.213)	Prec@5 96.875 (99.041)
Test: [0/48]	Time 4.310 (4.310)	Loss 2.1799 (2.1799)	Prec@1 59.375 (59.375)	Prec@5 84.375 (84.375)
Test: [20/48]	Time 0.490 (0.720)	Loss 1.9190 (1.2037)	Prec@1 59.375 (70.536)	Prec@5 87.500 (94.048)
Test: [40/48]	Time 0.472 (0.602)	Loss 1.2560 (1.1598)	Prec@1 68.750 (71.646)	Prec@5 93.750 (93.674)
Testing Results: Prec@1 70.980 Prec@5 93.595 Loss 1.19105
Best Prec@1: 71.830

Freezing BatchNorm2D except the first one.
Epoch: [14][0/111], lr: 0.00010	Time 6.697 (6.697)	Data 5.057 (5.057)	Loss 0.3902 (0.3902)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Epoch: [14][20/111], lr: 0.00010	Time 1.603 (1.847)	Data 0.000 (0.241)	Loss 0.4587 (0.3146)	Prec@1 93.750 (90.327)	Prec@5 93.750 (98.363)
Epoch: [14][40/111], lr: 0.00010	Time 1.603 (1.733)	Data 0.000 (0.124)	Loss 0.5420 (0.3003)	Prec@1 87.500 (90.549)	Prec@5 93.750 (98.552)
Epoch: [14][60/111], lr: 0.00010	Time 1.608 (1.691)	Data 0.000 (0.083)	Loss 0.2783 (0.2890)	Prec@1 90.625 (91.189)	Prec@5 96.875 (98.770)
Epoch: [14][80/111], lr: 0.00010	Time 1.608 (1.669)	Data 0.000 (0.063)	Loss 0.3634 (0.2970)	Prec@1 81.250 (90.972)	Prec@5 100.000 (98.534)
Epoch: [14][100/111], lr: 0.00010	Time 1.589 (1.656)	Data 0.000 (0.050)	Loss 0.1658 (0.2967)	Prec@1 93.750 (91.027)	Prec@5 100.000 (98.484)
Test: [0/48]	Time 5.571 (5.571)	Loss 2.1034 (2.1034)	Prec@1 59.375 (59.375)	Prec@5 81.250 (81.250)
Test: [20/48]	Time 0.467 (0.732)	Loss 1.8877 (1.1976)	Prec@1 62.500 (70.833)	Prec@5 87.500 (93.750)
Test: [40/48]	Time 0.468 (0.606)	Loss 1.1766 (1.1500)	Prec@1 78.125 (71.723)	Prec@5 93.750 (93.674)
Testing Results: Prec@1 71.373 Prec@5 93.399 Loss 1.17685
Best Prec@1: 71.830

Freezing BatchNorm2D except the first one.
Epoch: [15][0/111], lr: 0.00010	Time 5.421 (5.421)	Data 3.723 (3.723)	Loss 0.2633 (0.2633)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Epoch: [15][20/111], lr: 0.00010	Time 1.628 (1.794)	Data 0.000 (0.178)	Loss 0.2992 (0.2915)	Prec@1 93.750 (91.071)	Prec@5 100.000 (98.512)
Epoch: [15][40/111], lr: 0.00010	Time 1.623 (1.701)	Data 0.000 (0.091)	Loss 0.3964 (0.2915)	Prec@1 87.500 (90.473)	Prec@5 100.000 (98.933)
Epoch: [15][60/111], lr: 0.00010	Time 1.588 (1.669)	Data 0.000 (0.061)	Loss 0.3481 (0.2920)	Prec@1 90.625 (90.625)	Prec@5 100.000 (99.027)
Epoch: [15][80/111], lr: 0.00010	Time 1.608 (1.655)	Data 0.000 (0.046)	Loss 0.5020 (0.2888)	Prec@1 78.125 (90.934)	Prec@5 96.875 (98.920)
Epoch: [15][100/111], lr: 0.00010	Time 1.596 (1.646)	Data 0.000 (0.037)	Loss 0.0698 (0.2845)	Prec@1 100.000 (91.120)	Prec@5 100.000 (98.855)
Test: [0/48]	Time 4.008 (4.008)	Loss 2.2274 (2.2274)	Prec@1 59.375 (59.375)	Prec@5 81.250 (81.250)
Test: [20/48]	Time 0.472 (0.715)	Loss 1.9785 (1.2358)	Prec@1 59.375 (71.280)	Prec@5 87.500 (93.006)
Test: [40/48]	Time 0.466 (0.595)	Loss 1.2881 (1.1794)	Prec@1 65.625 (71.875)	Prec@5 93.750 (93.140)
Testing Results: Prec@1 71.111 Prec@5 93.203 Loss 1.20882
Best Prec@1: 71.830

Freezing BatchNorm2D except the first one.
Epoch: [16][0/111], lr: 0.00010	Time 6.064 (6.064)	Data 4.370 (4.370)	Loss 0.2810 (0.2810)	Prec@1 90.625 (90.625)	Prec@5 96.875 (96.875)
Epoch: [16][20/111], lr: 0.00010	Time 1.597 (1.813)	Data 0.000 (0.208)	Loss 0.3367 (0.2387)	Prec@1 90.625 (92.560)	Prec@5 100.000 (99.107)
Epoch: [16][40/111], lr: 0.00010	Time 1.590 (1.709)	Data 0.000 (0.107)	Loss 0.1884 (0.2456)	Prec@1 93.750 (93.216)	Prec@5 100.000 (99.162)
Epoch: [16][60/111], lr: 0.00010	Time 1.588 (1.677)	Data 0.000 (0.072)	Loss 0.6395 (0.2531)	Prec@1 81.250 (92.777)	Prec@5 96.875 (98.975)
Epoch: [16][80/111], lr: 0.00010	Time 1.591 (1.660)	Data 0.000 (0.054)	Loss 0.1278 (0.2593)	Prec@1 96.875 (92.323)	Prec@5 100.000 (98.920)
Epoch: [16][100/111], lr: 0.00010	Time 1.609 (1.649)	Data 0.000 (0.044)	Loss 0.2399 (0.2645)	Prec@1 96.875 (92.265)	Prec@5 100.000 (98.793)
Test: [0/48]	Time 4.605 (4.605)	Loss 2.1262 (2.1262)	Prec@1 62.500 (62.500)	Prec@5 84.375 (84.375)
Test: [20/48]	Time 0.487 (0.688)	Loss 1.9406 (1.2469)	Prec@1 59.375 (70.238)	Prec@5 84.375 (92.857)
Test: [40/48]	Time 0.468 (0.587)	Loss 1.2072 (1.1846)	Prec@1 71.875 (71.341)	Prec@5 93.750 (93.140)
Testing Results: Prec@1 71.111 Prec@5 93.072 Loss 1.21250
Best Prec@1: 71.830

Freezing BatchNorm2D except the first one.
Epoch: [17][0/111], lr: 0.00010	Time 5.193 (5.193)	Data 3.567 (3.567)	Loss 0.4340 (0.4340)	Prec@1 87.500 (87.500)	Prec@5 96.875 (96.875)
Epoch: [17][20/111], lr: 0.00010	Time 1.611 (1.781)	Data 0.000 (0.170)	Loss 0.3148 (0.3259)	Prec@1 87.500 (90.476)	Prec@5 100.000 (98.512)
Epoch: [17][40/111], lr: 0.00010	Time 1.599 (1.696)	Data 0.000 (0.087)	Loss 0.3336 (0.2768)	Prec@1 96.875 (92.073)	Prec@5 96.875 (98.780)
Epoch: [17][60/111], lr: 0.00010	Time 1.601 (1.672)	Data 0.000 (0.059)	Loss 0.1881 (0.2618)	Prec@1 93.750 (92.316)	Prec@5 100.000 (98.975)
Epoch: [17][80/111], lr: 0.00010	Time 1.604 (1.658)	Data 0.000 (0.044)	Loss 0.2075 (0.2615)	Prec@1 96.875 (92.284)	Prec@5 96.875 (98.997)
Epoch: [17][100/111], lr: 0.00010	Time 1.602 (1.654)	Data 0.000 (0.036)	Loss 0.1869 (0.2721)	Prec@1 93.750 (91.925)	Prec@5 100.000 (98.948)
Test: [0/48]	Time 5.268 (5.268)	Loss 2.2001 (2.2001)	Prec@1 59.375 (59.375)	Prec@5 84.375 (84.375)
Test: [20/48]	Time 0.514 (0.744)	Loss 2.0839 (1.2266)	Prec@1 56.250 (70.685)	Prec@5 87.500 (93.899)
Test: [40/48]	Time 0.466 (0.619)	Loss 1.2227 (1.1745)	Prec@1 78.125 (71.799)	Prec@5 93.750 (93.750)
Testing Results: Prec@1 71.176 Prec@5 93.660 Loss 1.20441
Best Prec@1: 71.830

Freezing BatchNorm2D except the first one.
Epoch: [18][0/111], lr: 0.00010	Time 7.005 (7.005)	Data 5.386 (5.386)	Loss 0.1570 (0.1570)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Epoch: [18][20/111], lr: 0.00010	Time 1.704 (1.885)	Data 0.000 (0.257)	Loss 0.1619 (0.2526)	Prec@1 100.000 (92.708)	Prec@5 100.000 (99.405)
Epoch: [18][40/111], lr: 0.00010	Time 1.597 (1.759)	Data 0.000 (0.132)	Loss 0.1956 (0.2449)	Prec@1 93.750 (92.378)	Prec@5 100.000 (99.543)
Epoch: [18][60/111], lr: 0.00010	Time 1.597 (1.714)	Data 0.000 (0.089)	Loss 0.1505 (0.2372)	Prec@1 93.750 (92.572)	Prec@5 100.000 (99.436)
Epoch: [18][80/111], lr: 0.00010	Time 1.596 (1.689)	Data 0.000 (0.067)	Loss 0.4000 (0.2342)	Prec@1 84.375 (92.747)	Prec@5 100.000 (99.537)
Epoch: [18][100/111], lr: 0.00010	Time 1.617 (1.675)	Data 0.000 (0.054)	Loss 0.3813 (0.2391)	Prec@1 93.750 (92.574)	Prec@5 93.750 (99.288)
Test: [0/48]	Time 5.756 (5.756)	Loss 2.2772 (2.2772)	Prec@1 59.375 (59.375)	Prec@5 81.250 (81.250)
Test: [20/48]	Time 0.476 (0.732)	Loss 2.0784 (1.2658)	Prec@1 59.375 (70.387)	Prec@5 84.375 (92.262)
Test: [40/48]	Time 0.488 (0.605)	Loss 1.2298 (1.2111)	Prec@1 75.000 (71.570)	Prec@5 93.750 (92.988)
Testing Results: Prec@1 71.176 Prec@5 93.072 Loss 1.24335
Best Prec@1: 71.830

Freezing BatchNorm2D except the first one.
Epoch: [19][0/111], lr: 0.00010	Time 6.787 (6.787)	Data 5.178 (5.178)	Loss 0.0642 (0.0642)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Epoch: [19][20/111], lr: 0.00010	Time 1.618 (1.877)	Data 0.000 (0.247)	Loss 0.3018 (0.2622)	Prec@1 87.500 (90.923)	Prec@5 96.875 (98.958)
Epoch: [19][40/111], lr: 0.00010	Time 1.672 (1.756)	Data 0.000 (0.126)	Loss 0.4667 (0.2747)	Prec@1 93.750 (91.692)	Prec@5 96.875 (98.704)
Epoch: [19][60/111], lr: 0.00010	Time 1.598 (1.719)	Data 0.000 (0.085)	Loss 0.1351 (0.2608)	Prec@1 96.875 (91.855)	Prec@5 100.000 (98.873)
Epoch: [19][80/111], lr: 0.00010	Time 1.606 (1.695)	Data 0.000 (0.064)	Loss 0.4368 (0.2568)	Prec@1 93.750 (91.937)	Prec@5 93.750 (98.997)
Epoch: [19][100/111], lr: 0.00010	Time 1.667 (1.683)	Data 0.000 (0.051)	Loss 0.1539 (0.2614)	Prec@1 96.875 (91.770)	Prec@5 100.000 (99.072)
Test: [0/48]	Time 5.947 (5.947)	Loss 2.3886 (2.3886)	Prec@1 59.375 (59.375)	Prec@5 78.125 (78.125)
Test: [20/48]	Time 0.473 (0.745)	Loss 1.9445 (1.2465)	Prec@1 59.375 (70.536)	Prec@5 84.375 (92.857)
Test: [40/48]	Time 0.467 (0.612)	Loss 1.2078 (1.1918)	Prec@1 81.250 (71.723)	Prec@5 93.750 (93.140)
Testing Results: Prec@1 71.438 Prec@5 93.007 Loss 1.22218
Best Prec@1: 71.830

Freezing BatchNorm2D except the first one.
Epoch: [20][0/111], lr: 0.00001	Time 6.186 (6.186)	Data 4.526 (4.526)	Loss 0.1993 (0.1993)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Epoch: [20][20/111], lr: 0.00001	Time 1.663 (1.832)	Data 0.000 (0.216)	Loss 0.0776 (0.2266)	Prec@1 100.000 (92.857)	Prec@5 100.000 (98.958)
Epoch: [20][40/111], lr: 0.00001	Time 1.603 (1.731)	Data 0.000 (0.111)	Loss 0.3321 (0.2358)	Prec@1 87.500 (92.454)	Prec@5 100.000 (99.085)
Epoch: [20][60/111], lr: 0.00001	Time 1.593 (1.699)	Data 0.000 (0.074)	Loss 0.3504 (0.2501)	Prec@1 87.500 (92.162)	Prec@5 100.000 (98.924)
Epoch: [20][80/111], lr: 0.00001	Time 1.627 (1.684)	Data 0.000 (0.056)	Loss 0.1281 (0.2563)	Prec@1 96.875 (91.975)	Prec@5 100.000 (98.843)
Epoch: [20][100/111], lr: 0.00001	Time 1.613 (1.673)	Data 0.000 (0.045)	Loss 0.0737 (0.2526)	Prec@1 96.875 (91.955)	Prec@5 100.000 (98.979)
Test: [0/48]	Time 5.880 (5.880)	Loss 2.3812 (2.3812)	Prec@1 59.375 (59.375)	Prec@5 78.125 (78.125)
Test: [20/48]	Time 0.471 (0.744)	Loss 2.0102 (1.2566)	Prec@1 59.375 (70.982)	Prec@5 84.375 (93.006)
Test: [40/48]	Time 0.470 (0.612)	Loss 1.2053 (1.2018)	Prec@1 81.250 (71.875)	Prec@5 93.750 (93.216)
Testing Results: Prec@1 71.503 Prec@5 93.007 Loss 1.23630
Best Prec@1: 71.830

Freezing BatchNorm2D except the first one.
Epoch: [21][0/111], lr: 0.00001	Time 5.299 (5.299)	Data 3.661 (3.661)	Loss 0.1420 (0.1420)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Epoch: [21][20/111], lr: 0.00001	Time 1.590 (1.799)	Data 0.000 (0.175)	Loss 0.1096 (0.2243)	Prec@1 96.875 (93.155)	Prec@5 100.000 (99.256)
Epoch: [21][40/111], lr: 0.00001	Time 1.601 (1.711)	Data 0.000 (0.089)	Loss 0.1271 (0.2173)	Prec@1 100.000 (93.598)	Prec@5 100.000 (99.314)
Epoch: [21][60/111], lr: 0.00001	Time 1.593 (1.687)	Data 0.000 (0.060)	Loss 0.3877 (0.2241)	Prec@1 90.625 (92.674)	Prec@5 96.875 (99.385)
Epoch: [21][80/111], lr: 0.00001	Time 1.593 (1.675)	Data 0.000 (0.045)	Loss 0.2260 (0.2230)	Prec@1 90.625 (92.824)	Prec@5 100.000 (99.228)
Epoch: [21][100/111], lr: 0.00001	Time 1.665 (1.667)	Data 0.000 (0.036)	Loss 0.1814 (0.2202)	Prec@1 93.750 (92.976)	Prec@5 100.000 (99.288)
Test: [0/48]	Time 4.861 (4.861)	Loss 2.3353 (2.3353)	Prec@1 59.375 (59.375)	Prec@5 78.125 (78.125)
Test: [20/48]	Time 0.487 (0.718)	Loss 2.0262 (1.2505)	Prec@1 59.375 (71.577)	Prec@5 84.375 (92.708)
Test: [40/48]	Time 0.467 (0.599)	Loss 1.1793 (1.1984)	Prec@1 81.250 (72.256)	Prec@5 93.750 (93.216)
Testing Results: Prec@1 71.895 Prec@5 93.137 Loss 1.23140
Best Prec@1: 71.895

Freezing BatchNorm2D except the first one.
Epoch: [22][0/111], lr: 0.00001	Time 7.032 (7.032)	Data 5.400 (5.400)	Loss 0.1058 (0.1058)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Epoch: [22][20/111], lr: 0.00001	Time 1.632 (1.874)	Data 0.000 (0.257)	Loss 0.2649 (0.2312)	Prec@1 84.375 (92.262)	Prec@5 100.000 (99.256)
Epoch: [22][40/111], lr: 0.00001	Time 1.598 (1.748)	Data 0.000 (0.132)	Loss 0.3916 (0.2698)	Prec@1 84.375 (91.159)	Prec@5 100.000 (98.857)
Epoch: [22][60/111], lr: 0.00001	Time 1.615 (1.703)	Data 0.000 (0.089)	Loss 0.0960 (0.2519)	Prec@1 100.000 (92.059)	Prec@5 100.000 (98.873)
Epoch: [22][80/111], lr: 0.00001	Time 1.605 (1.684)	Data 0.000 (0.067)	Loss 0.2701 (0.2428)	Prec@1 87.500 (92.168)	Prec@5 100.000 (98.997)
Epoch: [22][100/111], lr: 0.00001	Time 1.664 (1.673)	Data 0.000 (0.054)	Loss 0.3512 (0.2426)	Prec@1 93.750 (92.358)	Prec@5 96.875 (98.979)
Test: [0/48]	Time 4.903 (4.903)	Loss 2.3184 (2.3184)	Prec@1 59.375 (59.375)	Prec@5 81.250 (81.250)
Test: [20/48]	Time 0.489 (0.739)	Loss 2.0051 (1.2507)	Prec@1 56.250 (70.982)	Prec@5 87.500 (93.006)
Test: [40/48]	Time 0.474 (0.615)	Loss 1.1835 (1.1964)	Prec@1 78.125 (72.104)	Prec@5 93.750 (93.445)
Testing Results: Prec@1 71.699 Prec@5 93.399 Loss 1.22925
Best Prec@1: 71.895

Freezing BatchNorm2D except the first one.
Epoch: [23][0/111], lr: 0.00001	Time 6.828 (6.828)	Data 5.215 (5.215)	Loss 0.2307 (0.2307)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Epoch: [23][20/111], lr: 0.00001	Time 1.597 (1.856)	Data 0.000 (0.248)	Loss 0.2521 (0.2710)	Prec@1 90.625 (91.667)	Prec@5 100.000 (98.810)
Epoch: [23][40/111], lr: 0.00001	Time 1.603 (1.734)	Data 0.000 (0.127)	Loss 0.1178 (0.2550)	Prec@1 100.000 (92.226)	Prec@5 100.000 (98.933)
Epoch: [23][60/111], lr: 0.00001	Time 1.626 (1.698)	Data 0.000 (0.086)	Loss 0.2482 (0.2411)	Prec@1 90.625 (92.162)	Prec@5 96.875 (99.232)
Epoch: [23][80/111], lr: 0.00001	Time 1.600 (1.678)	Data 0.000 (0.065)	Loss 0.0854 (0.2300)	Prec@1 96.875 (92.670)	Prec@5 100.000 (99.228)
Epoch: [23][100/111], lr: 0.00001	Time 1.695 (1.670)	Data 0.000 (0.052)	Loss 0.2659 (0.2363)	Prec@1 93.750 (92.574)	Prec@5 96.875 (99.165)
Test: [0/48]	Time 4.353 (4.353)	Loss 2.2677 (2.2677)	Prec@1 59.375 (59.375)	Prec@5 81.250 (81.250)
Test: [20/48]	Time 0.490 (0.699)	Loss 2.0510 (1.2542)	Prec@1 56.250 (70.833)	Prec@5 87.500 (93.006)
Test: [40/48]	Time 0.470 (0.596)	Loss 1.1658 (1.2051)	Prec@1 81.250 (71.875)	Prec@5 93.750 (93.521)
Testing Results: Prec@1 71.503 Prec@5 93.333 Loss 1.23776
Best Prec@1: 71.895

Freezing BatchNorm2D except the first one.
Epoch: [24][0/111], lr: 0.00001	Time 7.195 (7.195)	Data 5.499 (5.499)	Loss 0.0520 (0.0520)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Epoch: [24][20/111], lr: 0.00001	Time 1.596 (1.876)	Data 0.000 (0.262)	Loss 0.5731 (0.2145)	Prec@1 84.375 (92.708)	Prec@5 96.875 (99.554)
Epoch: [24][40/111], lr: 0.00001	Time 1.597 (1.750)	Data 0.000 (0.134)	Loss 0.3779 (0.2224)	Prec@1 87.500 (92.759)	Prec@5 96.875 (99.162)
Epoch: [24][60/111], lr: 0.00001	Time 1.613 (1.706)	Data 0.000 (0.090)	Loss 0.1308 (0.2165)	Prec@1 93.750 (93.033)	Prec@5 100.000 (99.232)
Epoch: [24][80/111], lr: 0.00001	Time 1.595 (1.681)	Data 0.000 (0.068)	Loss 0.2660 (0.2248)	Prec@1 93.750 (92.785)	Prec@5 100.000 (99.151)
Epoch: [24][100/111], lr: 0.00001	Time 1.713 (1.669)	Data 0.000 (0.055)	Loss 0.3569 (0.2244)	Prec@1 96.875 (93.007)	Prec@5 96.875 (99.041)
Test: [0/48]	Time 5.411 (5.411)	Loss 2.3012 (2.3012)	Prec@1 59.375 (59.375)	Prec@5 81.250 (81.250)
Test: [20/48]	Time 0.470 (0.721)	Loss 2.0591 (1.2551)	Prec@1 56.250 (70.685)	Prec@5 87.500 (93.452)
Test: [40/48]	Time 0.463 (0.602)	Loss 1.1752 (1.2089)	Prec@1 81.250 (71.951)	Prec@5 93.750 (93.598)
Testing Results: Prec@1 71.569 Prec@5 93.595 Loss 1.24062
Best Prec@1: 71.895

